{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler\n",
    "X_ppg,X_qual,X_acc,y_rr,y_respiration,y_inspiration,y_expiration,groups,X_respiration,y_activity,y_label = pickle.load(open('../../affect-recognition/data/tabular_data_8.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "index = np.where((y_activity!=0)&(y_activity!=3)&(y_activity!=6)&(y_activity!=8))[0]\n",
    "X_acc = X_acc[index]\n",
    "y_activity = y_activity[index]\n",
    "groups = groups[index]\n",
    "y_activity = OneHotEncoder().fit_transform(y_activity.reshape(-1,1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fft = np.fft.fft(X_acc[:,:,:],axis=1)\n",
    "X_fft_real = X_fft.real\n",
    "X_fft_imag = X_fft.imag\n",
    "X_fft = np.concatenate([X_fft_real,X_fft_imag],axis=2)\n",
    "max_value = X_fft.max()\n",
    "X_fft = X_fft/max_value\n",
    "X_fft.shape,X_acc.shape\n",
    "max_value = X_acc.max()\n",
    "X_acc = X_acc/max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 5)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 1, 5)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 1, 1, 32)     1632        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 32)        0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 1, 32)     0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 1, 1, 128)    41088       lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 128)       0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 1, 128)    0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 1, 1, 256)    327936      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 256)       0           conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 256, 3)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 256, 1)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 4)       0           input_2[0][0]                    \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 256, 100)     1700        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 256, 100)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 128, 100)     0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 100)     0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 128, 100)     80100       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 128, 100)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 64, 100)      0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 64, 100)      80100       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 64, 100)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 16, 100)      0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 100)      0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1600)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           48030       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            31          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,617\n",
      "Trainable params: 580,617\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 5)         0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 100)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1, 1, 5)      0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1, 1, 100)    0           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 1, 1, 32)     1632        lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 1, 1, 128)    128128      lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 32)        0           conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 128)       0           conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1, 1, 32)     0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1, 1, 128)    0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 1, 1, 256)    82176       lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 1, 1, 256)    327936      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 256)       0           conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 256)       0           conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 256, 1)       0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 256, 1)       0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 2)       0           reshape_4[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 256, 100)     8100        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 256, 3)       15003       conv1d_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 562,975\n",
      "Trainable params: 562,975\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 256, 3)       562975      input_4[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            580617      model_2[1][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,143,592\n",
      "Trainable params: 562,975\n",
      "Non-trainable params: 580,617\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 5)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 1, 5)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 1, 1, 32)     1632        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 32)        0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 1, 32)     0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 1, 1, 128)    41088       lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 128)       0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 1, 128)    0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 1, 1, 256)    327936      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 256)       0           conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 256, 3)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 256, 1)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 4)       0           input_2[0][0]                    \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 256, 100)     1700        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 256, 100)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 128, 100)     0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 100)     0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 128, 100)     80100       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 128, 100)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 64, 100)      0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 64, 100)      80100       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 64, 100)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 16, 100)      0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 100)      0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1600)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           48030       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            31          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,161,234\n",
      "Trainable params: 580,617\n",
      "Non-trainable params: 580,617\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ea842e5b8490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;31m# d_model.add_loss(wasserstein_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;31m# d_model.add_metric('accuracy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_activity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;31m# train(g_model, c_model, gan_model, dataset, latent_dim=100, n_epochs=10, n_batch=128, n_critic=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_acc' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,GRU,Bidirectional\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten,multiply\n",
    "from keras.layers import Conv2D,Conv1D,MaxPool1D,BatchNormalization\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv2DTranspose, Lambda\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# clip model weights to a given hypercube\n",
    "class ClipConstraint(Constraint):\n",
    "    # set clip value when initialized\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    # clip model weights to hypercube\n",
    "    def __call__(self, weights):\n",
    "        return K.clip(weights, -self.clip_value, self.clip_value)\n",
    "\n",
    "    # get the config\n",
    "    def get_config(self):\n",
    "        return {'clip_value': self.clip_value}\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "def Conv1DTranspose(input_tensor, filters, kernel_size, strides=1, padding='same'):\n",
    "    \"\"\"\n",
    "        input_tensor: tensor, with the shape (batch_size, time_steps, dims)\n",
    "        filters: int, output dimension, i.e. the output tensor will have the shape of (batch_size, time_steps, filters)\n",
    "        kernel_size: int, size of the convolution kernel\n",
    "        strides: int, convolution step size\n",
    "        padding: 'same' | 'valid'\n",
    "    \"\"\"\n",
    "    x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), \n",
    "                        strides=(strides, 1), padding=padding,activation='tanh',\n",
    "                       kernel_initializer='he_normal')(x)\n",
    "    x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def define_discriminator(in_shape=(256,3), n_classes=5):\n",
    "    const = ClipConstraint(.1)\n",
    "    in_label = Input(shape=(n_classes,))\n",
    "    li = Reshape((1,n_classes))(in_label)\n",
    "    li = Conv1DTranspose(li,32,10)\n",
    "    li = Conv1DTranspose(li,128,10)\n",
    "    li = Conv1DTranspose(li,256,10)\n",
    "    li = Reshape((in_shape[0],1))(li)\n",
    "    in_image = Input(shape=in_shape)\n",
    "    merge = Concatenate()([in_image, li])\n",
    "    fe = Conv1D(100,4, padding='same',activation='linear',kernel_initializer='he_normal',kernel_constraint=const)(merge)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = MaxPool1D(2)(fe)\n",
    "    fe = Dropout(0.2)(fe)\n",
    "    fe = Conv1D(100,8,padding='same',kernel_initializer='he_normal',kernel_constraint=const)(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = MaxPool1D(2)(fe)\n",
    "    fe = Conv1D(100,8,padding='same',kernel_initializer='he_normal',kernel_constraint=const)(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = MaxPool1D(4)(fe)\n",
    "    fe = Dropout(0.4)(fe)\n",
    "    fe = Flatten()(fe)\n",
    "    fe  = Dense(30,kernel_initializer='he_normal',kernel_constraint=const)(fe)\n",
    "    out_layer = Dense(1, activation='linear',kernel_initializer='he_normal')(fe)\n",
    "    opt = RMSprop(lr=1e-6)\n",
    "    model = Model([in_image,in_label],out_layer)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def define_generator(latent_dim=100, n_classes=5,out_shape=(256,3)):\n",
    "    in_label = Input(shape=(n_classes,))\n",
    "    li = Reshape((1,n_classes))(in_label)\n",
    "    li = Conv1DTranspose(li,32,10)\n",
    "#     li = LeakyReLU(alpha=0.2)(li)\n",
    "#     li = Conv1DTranspose(li,64,10)\n",
    "#     li = LeakyReLU(alpha=0.2)(li)\n",
    "#     li = Conv1DTranspose(li,128,10)\n",
    "#     li = LeakyReLU(alpha=0.2)(li)\n",
    "    li = Conv1DTranspose(li,256,10)\n",
    "    li = Reshape((out_shape[0],1))(li)\n",
    "    in_noise = Input(shape=(latent_dim,))\n",
    "    li1 = Reshape((1,latent_dim))(in_noise)\n",
    "#     li1 = Conv1DTranspose(li1,32,10)\n",
    "#     li1 = LeakyReLU(alpha=0.2)(li1)\n",
    "#     li1 = Conv1DTranspose(li1,64,10)\n",
    "#     li1 = LeakyReLU(alpha=0.2)(li1)\n",
    "    li1 = Conv1DTranspose(li1,128,10)\n",
    "#     li1 = LeakyReLU(alpha=0.2)(li1)\n",
    "    li1 = Conv1DTranspose(li1,256,10)\n",
    "    li1 = Reshape((out_shape[0],1))(li1)\n",
    "    li = Concatenate()([li,li1])\n",
    "    li = Conv1D(100,40, padding='same',activation='tanh',kernel_initializer='he_normal')(li)\n",
    "#     li = Dropout(.2)(li)\n",
    "    li = Conv1D(out_shape[1],50, padding='same',activation='tanh',kernel_initializer='he_normal')(li)\n",
    "    model = Model([in_noise,in_label],li)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def define_gan(g_model, c_model):\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    gen_output = g_model(g_model.input)\n",
    "    c_model.trainable = False\n",
    "    gan_output = c_model([gen_output, gen_label])\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    opt = RMSprop(lr=1e-6)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    images, labels = dataset\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y\n",
    "\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=5):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input/x_input.max()\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    labels = OneHotEncoder().fit_transform(labels.reshape(-1,1)).todense()\n",
    "    return [z_input, labels]\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples,plot=False):\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    images = generator.predict([z_input, labels_input])\n",
    "    if plot and np.argmax(labels_input[0].reshape(-1))==0:\n",
    "        plt.figure()\n",
    "        plt.plot(images[0]*max_value)\n",
    "        plt.title(np.argmax(labels_input[0].reshape(-1)))\n",
    "        plt.ylabel('Fake')\n",
    "        plt.show()\n",
    "    y = -1*ones((n_samples, 1))\n",
    "    return [images, labels_input], y\n",
    "\n",
    "def plot_history(d1_hist, d2_hist, g_hist):\n",
    "# plot history\n",
    "    plt.plot(d1_hist, label='crit_real')\n",
    "    plt.plot(d2_hist, label='crit_fake')\n",
    "    plt.plot(g_hist, label='gen')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     plt.savefig('plot_line_plot_loss.png')\n",
    "#     pyplot.close()\n",
    "\n",
    "def train(g_model, c_model, gan_model, dataset, latent_dim=100, n_epochs=10, n_batch=128, n_critic=1):\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    indexes = StratifiedKFold(n_splits=bat_per_epo).split(dataset[0],np.argmax(dataset[1],axis=1))\n",
    "    data_all = [[dataset[0][test],dataset[1][test]] for _,test in indexes]\n",
    "    half_batch = int(n_batch / 2)\n",
    "    c1_hist, c2_hist, g_hist = list(), list(), list()\n",
    "    for i in range(n_epochs):\n",
    "        c1_tmp, c2_tmp = list(), list()\n",
    "#         c_model.trainable = True\n",
    "        for j,data in enumerate(data_all):\n",
    "            c_model.trainable = True\n",
    "            for _ in range(n_critic):\n",
    "                [X_real,label_real], y_real = generate_real_samples(dataset,data[0].shape[0])\n",
    "#                 X_real,label_real = data\n",
    "                c_loss1 = c_model.train_on_batch([X_real,label_real], y_real)\n",
    "                c1_tmp.append(c_loss1)\n",
    "                if j%10==0:\n",
    "                    plot=True\n",
    "                else:\n",
    "                    plot=False\n",
    "                [X_fake,label_false], y_fake = generate_fake_samples(g_model, latent_dim,data[0].shape[0],plot)\n",
    "                c_loss2 = c_model.train_on_batch([X_fake,label_false], y_fake)\n",
    "                c2_tmp.append(c_loss2)\n",
    "#             print(g_model.weights[0][0][0][:5])\n",
    "            c_model.trainable = False\n",
    "            # prepare points in latent space as input for the generator\n",
    "            z_input, label_fake = generate_latent_points(latent_dim, n_batch*5)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = -1*ones((n_batch*5, 1))\n",
    "            # update the generator via the critic's error\n",
    "            g_loss = gan_model.train_on_batch([z_input,label_fake], y_gan)\n",
    "            g_hist.append(g_loss)\n",
    "            c1_hist.append(np.mean(c1_tmp))\n",
    "            c2_hist.append(np.mean(c2_tmp))\n",
    "#             print(g_model.weights[0][0][0][:5])\n",
    "            # summarize loss on this batch\n",
    "            print('>%d, >%d,>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1,j,len(data_all), c1_hist[-1], c2_hist[-1], g_loss))\n",
    "            # evaluate the model performance every 'epoch'\n",
    "            if (i+1) % bat_per_epo == 0:\n",
    "                summarize_performance(i, g_model, latent_dim)\n",
    "    # line plots of loss\n",
    "    plot_history(c1_hist, c2_hist, g_hist)\n",
    "\n",
    "c_model = define_discriminator()\n",
    "g_model = define_generator()\n",
    "gan_model = define_gan(g_model,c_model)\n",
    "c_model.summary()\n",
    "# d_model.optimizer = opt\n",
    "# d_model.add_loss(wasserstein_loss)\n",
    "# d_model.add_metric('accuracy')\n",
    "dataset = [X_acc, y_activity]\n",
    "# train(g_model, c_model, gan_model, dataset, latent_dim=100, n_epochs=10, n_batch=128, n_critic=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[-0.04429895,  0.0671236 , -0.04683576,  0.06442928, -0.08445578],\n",
       "       [ 0.15821798, -0.04040162, -0.06376234,  0.05322482,  0.01867284],\n",
       "       [-0.05572864,  0.07082803,  0.05174615,  0.02109903,  0.04598693],\n",
       "       [ 0.03222822,  0.02668047,  0.00503553,  0.03536528,  0.11152425],\n",
       "       [ 0.06771738, -0.07430615,  0.09174889, -0.04474792,  0.00757073]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_model.weights[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 256)         439296    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_1 (SeqSel (None, None, 256)         16449     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 5)           1285      \n",
      "=================================================================\n",
      "Total params: 3,457,030\n",
      "Trainable params: 3,457,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim=10000,\n",
    "                                 output_dim=300,\n",
    "                                 mask_zero=True))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128,\n",
    "                                                       return_sequences=True)))\n",
    "model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(units=5))\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "train shape: (60000, 28, 28)\n",
      "test shape: (10000, 28, 28)\n",
      "{0: 6000, 1: 6000, 2: 6000, 3: 6000, 4: 6000, 5: 6000, 6: 6000, 7: 6000, 8: 6000, 9: 6000}\n",
      "train shape after reshape: (60000, 1, 28, 28)\n",
      "test shape after reshape: (10000, 1, 28, 28)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 1, 28, 32)         22432     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 1, 14, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 1, 14, 64)         51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 1, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 1, 7, 128)         8320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 1, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,137,258\n",
      "Trainable params: 1,137,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/150\n",
      " - 3s - loss: 1.7062 - accuracy: 0.3787 - val_loss: 0.7961 - val_accuracy: 0.6975\n",
      "Epoch 2/150\n",
      " - 3s - loss: 0.7400 - accuracy: 0.7262 - val_loss: 0.6206 - val_accuracy: 0.7621\n",
      "Epoch 3/150\n",
      " - 2s - loss: 0.6245 - accuracy: 0.7693 - val_loss: 0.5652 - val_accuracy: 0.7932\n",
      "Epoch 4/150\n",
      " - 2s - loss: 0.5773 - accuracy: 0.7874 - val_loss: 0.5290 - val_accuracy: 0.8038\n",
      "Epoch 5/150\n",
      " - 2s - loss: 0.5417 - accuracy: 0.8023 - val_loss: 0.5035 - val_accuracy: 0.8124\n",
      "Epoch 6/150\n",
      " - 3s - loss: 0.5131 - accuracy: 0.8135 - val_loss: 0.4823 - val_accuracy: 0.8214\n",
      "Epoch 7/150\n",
      " - 2s - loss: 0.4903 - accuracy: 0.8204 - val_loss: 0.4683 - val_accuracy: 0.8260\n",
      "Epoch 8/150\n",
      " - 2s - loss: 0.4684 - accuracy: 0.8308 - val_loss: 0.4470 - val_accuracy: 0.8349\n",
      "Epoch 9/150\n",
      " - 2s - loss: 0.4489 - accuracy: 0.8372 - val_loss: 0.4435 - val_accuracy: 0.8364\n",
      "Epoch 10/150\n",
      " - 2s - loss: 0.4327 - accuracy: 0.8414 - val_loss: 0.4146 - val_accuracy: 0.8456\n",
      "Epoch 11/150\n",
      " - 2s - loss: 0.4136 - accuracy: 0.8486 - val_loss: 0.4063 - val_accuracy: 0.8512\n",
      "Epoch 12/150\n",
      " - 2s - loss: 0.4029 - accuracy: 0.8529 - val_loss: 0.3985 - val_accuracy: 0.8547\n",
      "Epoch 13/150\n",
      " - 2s - loss: 0.3908 - accuracy: 0.8578 - val_loss: 0.3860 - val_accuracy: 0.8600\n",
      "Epoch 14/150\n",
      " - 2s - loss: 0.3786 - accuracy: 0.8616 - val_loss: 0.3801 - val_accuracy: 0.8610\n",
      "Epoch 15/150\n",
      " - 2s - loss: 0.3711 - accuracy: 0.8657 - val_loss: 0.3690 - val_accuracy: 0.8657\n",
      "Epoch 16/150\n",
      " - 2s - loss: 0.3620 - accuracy: 0.8687 - val_loss: 0.3754 - val_accuracy: 0.8636\n",
      "Epoch 17/150\n",
      " - 2s - loss: 0.3577 - accuracy: 0.8704 - val_loss: 0.3622 - val_accuracy: 0.8694\n",
      "Epoch 18/150\n",
      " - 3s - loss: 0.3494 - accuracy: 0.8730 - val_loss: 0.3557 - val_accuracy: 0.8724\n",
      "Epoch 19/150\n",
      " - 2s - loss: 0.3455 - accuracy: 0.8751 - val_loss: 0.3499 - val_accuracy: 0.8747\n",
      "Epoch 20/150\n",
      " - 2s - loss: 0.3383 - accuracy: 0.8769 - val_loss: 0.3452 - val_accuracy: 0.8763\n",
      "Epoch 21/150\n",
      " - 2s - loss: 0.3343 - accuracy: 0.8780 - val_loss: 0.3523 - val_accuracy: 0.8728\n",
      "Epoch 22/150\n",
      " - 2s - loss: 0.3285 - accuracy: 0.8813 - val_loss: 0.3432 - val_accuracy: 0.8735\n",
      "Epoch 23/150\n",
      " - 2s - loss: 0.3226 - accuracy: 0.8831 - val_loss: 0.3393 - val_accuracy: 0.8778\n",
      "Epoch 24/150\n",
      " - 2s - loss: 0.3187 - accuracy: 0.8841 - val_loss: 0.3362 - val_accuracy: 0.8796\n",
      "Epoch 25/150\n",
      " - 3s - loss: 0.3153 - accuracy: 0.8860 - val_loss: 0.3291 - val_accuracy: 0.8829\n",
      "Epoch 26/150\n",
      " - 2s - loss: 0.3105 - accuracy: 0.8868 - val_loss: 0.3298 - val_accuracy: 0.8801\n",
      "Epoch 27/150\n",
      " - 2s - loss: 0.3076 - accuracy: 0.8871 - val_loss: 0.3304 - val_accuracy: 0.8802\n",
      "Epoch 28/150\n",
      " - 2s - loss: 0.3014 - accuracy: 0.8902 - val_loss: 0.3268 - val_accuracy: 0.8821\n",
      "Epoch 29/150\n",
      " - 2s - loss: 0.3000 - accuracy: 0.8910 - val_loss: 0.3216 - val_accuracy: 0.8863\n",
      "Epoch 30/150\n",
      " - 2s - loss: 0.2974 - accuracy: 0.8917 - val_loss: 0.3244 - val_accuracy: 0.8847\n",
      "Epoch 31/150\n",
      " - 2s - loss: 0.2932 - accuracy: 0.8930 - val_loss: 0.3209 - val_accuracy: 0.8848\n",
      "Epoch 32/150\n",
      " - 2s - loss: 0.2910 - accuracy: 0.8932 - val_loss: 0.3141 - val_accuracy: 0.8882\n",
      "Epoch 33/150\n",
      " - 3s - loss: 0.2878 - accuracy: 0.8954 - val_loss: 0.3130 - val_accuracy: 0.8882\n",
      "Epoch 34/150\n",
      " - 2s - loss: 0.2842 - accuracy: 0.8972 - val_loss: 0.3139 - val_accuracy: 0.8885\n",
      "Epoch 35/150\n",
      " - 2s - loss: 0.2829 - accuracy: 0.8969 - val_loss: 0.3167 - val_accuracy: 0.8868\n",
      "Epoch 36/150\n",
      " - 2s - loss: 0.2805 - accuracy: 0.8986 - val_loss: 0.3124 - val_accuracy: 0.8878\n",
      "Epoch 37/150\n",
      " - 2s - loss: 0.2756 - accuracy: 0.8997 - val_loss: 0.3068 - val_accuracy: 0.8901\n",
      "Epoch 38/150\n",
      " - 2s - loss: 0.2748 - accuracy: 0.8990 - val_loss: 0.3039 - val_accuracy: 0.8904\n",
      "Epoch 39/150\n",
      " - 2s - loss: 0.2715 - accuracy: 0.9017 - val_loss: 0.3042 - val_accuracy: 0.8911\n",
      "Epoch 40/150\n",
      " - 2s - loss: 0.2685 - accuracy: 0.9020 - val_loss: 0.3004 - val_accuracy: 0.8908\n",
      "Epoch 41/150\n",
      " - 2s - loss: 0.2675 - accuracy: 0.9017 - val_loss: 0.2996 - val_accuracy: 0.8949\n",
      "Epoch 42/150\n",
      " - 2s - loss: 0.2639 - accuracy: 0.9027 - val_loss: 0.3008 - val_accuracy: 0.8928\n",
      "Epoch 43/150\n",
      " - 2s - loss: 0.2638 - accuracy: 0.9039 - val_loss: 0.2954 - val_accuracy: 0.8944\n",
      "Epoch 44/150\n",
      " - 3s - loss: 0.2598 - accuracy: 0.9040 - val_loss: 0.2979 - val_accuracy: 0.8957\n",
      "Epoch 45/150\n",
      " - 3s - loss: 0.2586 - accuracy: 0.9049 - val_loss: 0.2949 - val_accuracy: 0.8949\n",
      "Epoch 46/150\n",
      " - 3s - loss: 0.2564 - accuracy: 0.9069 - val_loss: 0.2983 - val_accuracy: 0.8926\n",
      "Epoch 47/150\n",
      " - 3s - loss: 0.2555 - accuracy: 0.9073 - val_loss: 0.2954 - val_accuracy: 0.8934\n",
      "Epoch 48/150\n",
      " - 2s - loss: 0.2531 - accuracy: 0.9071 - val_loss: 0.2959 - val_accuracy: 0.8940\n",
      "Epoch 49/150\n",
      " - 2s - loss: 0.2502 - accuracy: 0.9088 - val_loss: 0.2911 - val_accuracy: 0.8954\n",
      "Epoch 50/150\n",
      " - 2s - loss: 0.2501 - accuracy: 0.9086 - val_loss: 0.2923 - val_accuracy: 0.8967\n",
      "Epoch 51/150\n",
      " - 2s - loss: 0.2470 - accuracy: 0.9093 - val_loss: 0.2889 - val_accuracy: 0.8974\n",
      "Epoch 52/150\n",
      " - 2s - loss: 0.2461 - accuracy: 0.9100 - val_loss: 0.2918 - val_accuracy: 0.8969\n",
      "Epoch 53/150\n",
      " - 2s - loss: 0.2434 - accuracy: 0.9098 - val_loss: 0.2944 - val_accuracy: 0.8969\n",
      "Epoch 54/150\n",
      " - 2s - loss: 0.2424 - accuracy: 0.9112 - val_loss: 0.2932 - val_accuracy: 0.8973\n",
      "Epoch 55/150\n",
      " - 2s - loss: 0.2388 - accuracy: 0.9123 - val_loss: 0.2824 - val_accuracy: 0.9007\n",
      "Epoch 56/150\n",
      " - 3s - loss: 0.2402 - accuracy: 0.9114 - val_loss: 0.2851 - val_accuracy: 0.8992\n",
      "Epoch 57/150\n",
      " - 2s - loss: 0.2369 - accuracy: 0.9133 - val_loss: 0.2923 - val_accuracy: 0.8950\n",
      "Epoch 58/150\n",
      " - 2s - loss: 0.2355 - accuracy: 0.9146 - val_loss: 0.2858 - val_accuracy: 0.8976\n",
      "Epoch 59/150\n",
      " - 2s - loss: 0.2343 - accuracy: 0.9131 - val_loss: 0.2819 - val_accuracy: 0.9008\n",
      "Epoch 60/150\n",
      " - 2s - loss: 0.2302 - accuracy: 0.9151 - val_loss: 0.2852 - val_accuracy: 0.8994\n",
      "Epoch 61/150\n",
      " - 3s - loss: 0.2306 - accuracy: 0.9153 - val_loss: 0.2804 - val_accuracy: 0.9014\n",
      "Epoch 62/150\n",
      " - 2s - loss: 0.2281 - accuracy: 0.9151 - val_loss: 0.2807 - val_accuracy: 0.9013\n",
      "Epoch 63/150\n",
      " - 2s - loss: 0.2276 - accuracy: 0.9161 - val_loss: 0.2836 - val_accuracy: 0.8991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/150\n",
      " - 2s - loss: 0.2259 - accuracy: 0.9178 - val_loss: 0.2785 - val_accuracy: 0.9011\n",
      "Epoch 65/150\n",
      " - 2s - loss: 0.2237 - accuracy: 0.9185 - val_loss: 0.2789 - val_accuracy: 0.9021\n",
      "Epoch 66/150\n",
      " - 2s - loss: 0.2225 - accuracy: 0.9192 - val_loss: 0.2767 - val_accuracy: 0.9018\n",
      "Epoch 67/150\n",
      " - 2s - loss: 0.2226 - accuracy: 0.9175 - val_loss: 0.2791 - val_accuracy: 0.9007\n",
      "Epoch 68/150\n",
      " - 2s - loss: 0.2186 - accuracy: 0.9203 - val_loss: 0.2756 - val_accuracy: 0.9031\n",
      "Epoch 69/150\n",
      " - 2s - loss: 0.2172 - accuracy: 0.9199 - val_loss: 0.2775 - val_accuracy: 0.9025\n",
      "Epoch 70/150\n",
      " - 2s - loss: 0.2166 - accuracy: 0.9194 - val_loss: 0.2789 - val_accuracy: 0.9006\n",
      "Epoch 71/150\n",
      " - 2s - loss: 0.2151 - accuracy: 0.9207 - val_loss: 0.2742 - val_accuracy: 0.9021\n",
      "Epoch 72/150\n",
      " - 2s - loss: 0.2137 - accuracy: 0.9206 - val_loss: 0.2761 - val_accuracy: 0.9048\n",
      "Epoch 73/150\n",
      " - 2s - loss: 0.2134 - accuracy: 0.9212 - val_loss: 0.2793 - val_accuracy: 0.9012\n",
      "Epoch 74/150\n",
      " - 2s - loss: 0.2124 - accuracy: 0.9221 - val_loss: 0.2761 - val_accuracy: 0.9013\n",
      "Epoch 75/150\n",
      " - 2s - loss: 0.2101 - accuracy: 0.9230 - val_loss: 0.2735 - val_accuracy: 0.9015\n",
      "Epoch 76/150\n",
      " - 2s - loss: 0.2100 - accuracy: 0.9224 - val_loss: 0.2758 - val_accuracy: 0.9038\n",
      "Epoch 77/150\n",
      " - 3s - loss: 0.2077 - accuracy: 0.9235 - val_loss: 0.2760 - val_accuracy: 0.9012\n",
      "Epoch 78/150\n",
      " - 2s - loss: 0.2057 - accuracy: 0.9232 - val_loss: 0.2738 - val_accuracy: 0.9053\n",
      "Epoch 79/150\n",
      " - 2s - loss: 0.2054 - accuracy: 0.9234 - val_loss: 0.2818 - val_accuracy: 0.9041\n",
      "Epoch 80/150\n",
      " - 3s - loss: 0.2033 - accuracy: 0.9253 - val_loss: 0.2774 - val_accuracy: 0.9051\n",
      "Epoch 81/150\n",
      " - 2s - loss: 0.2028 - accuracy: 0.9251 - val_loss: 0.2738 - val_accuracy: 0.9053\n",
      "Epoch 82/150\n",
      " - 2s - loss: 0.2026 - accuracy: 0.9251 - val_loss: 0.2746 - val_accuracy: 0.9048\n",
      "Epoch 83/150\n",
      " - 2s - loss: 0.2008 - accuracy: 0.9256 - val_loss: 0.2743 - val_accuracy: 0.9045\n",
      "Epoch 84/150\n",
      " - 3s - loss: 0.1993 - accuracy: 0.9263 - val_loss: 0.2745 - val_accuracy: 0.9053\n",
      "Epoch 85/150\n",
      " - 2s - loss: 0.1997 - accuracy: 0.9261 - val_loss: 0.2752 - val_accuracy: 0.9049\n",
      "Epoch 86/150\n",
      " - 2s - loss: 0.1951 - accuracy: 0.9273 - val_loss: 0.2765 - val_accuracy: 0.9031\n",
      "Epoch 87/150\n",
      " - 2s - loss: 0.1958 - accuracy: 0.9274 - val_loss: 0.2810 - val_accuracy: 0.9018\n",
      "Epoch 88/150\n",
      " - 2s - loss: 0.1948 - accuracy: 0.9281 - val_loss: 0.2730 - val_accuracy: 0.9046\n",
      "Epoch 00088: early stopping\n",
      "Error: 9.54%\n",
      "Accuracy: 90.46%\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6aa6c1ec19f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-6aa6c1ec19f4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mfig_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np  # linear algebra\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math as mt\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.models import Sequential,Input\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import MaxPooling2D,Multiply,multiply\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# K.set_image_dim_ordering('th')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define path to save model\n",
    "model_path_cnn = '../../affect-recognition/data/pic1/a.h5'\n",
    "\n",
    "# training configuration\n",
    "batch_size = 400\n",
    "epochs = 150\n",
    "# prepare callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        verbose=1),\n",
    "    ModelCheckpoint(\n",
    "        model_path_cnn,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=0)\n",
    "]\n",
    "\n",
    "# k-fold configuration\n",
    "n_splits = 5\n",
    "\n",
    "\n",
    "def average(numbers):\n",
    "    \"\"\"\n",
    "    Return the sample arithmetic mean of data.\n",
    "    :param numbers: a list of float\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(sum(numbers)) / max(len(numbers), 1)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def sum_of_square_deviation(numbers, mean):\n",
    "    \"\"\"\n",
    "    Return sum of square deviations of sequence data.\n",
    "    :param numbers: a list of float\n",
    "    :param mean:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(1 / len(numbers) * sum((x - mean) ** 2 for x in numbers))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "from keras_self_attention import SeqSelfAttention,ScaledDotProductAttention\n",
    "\n",
    "def model_cnn2(num_classes):\n",
    "    \"\"\"Convolutional Neural Network\n",
    "\n",
    "    The network topology can be summarized as follows:\n",
    "\n",
    "        Convolutional layer with 32 feature maps of size 5×5.\n",
    "        Pooling layer taking the max over 2*2 patches.\n",
    "        Convolutional layer with 64 feature maps of size 5×5.\n",
    "        Pooling layer taking the max over 2*2 patches.\n",
    "        Convolutional layer with 128 feature maps of size 1×1.\n",
    "        Pooling layer taking the max over 2*2 patches.\n",
    "        Flatten layer.\n",
    "        Fully connected layer with 1024 neurons and rectifier activation.\n",
    "        Dropout layer with a probability of 50%.\n",
    "        Fully connected layer with 510 neurons and rectifier activation.\n",
    "        Dropout layer with a probability of 50%.\n",
    "        Output layer.\n",
    "\n",
    "    \"\"\"\n",
    "    # create model\n",
    "#     model = Sequential()\n",
    "    inputs = Input(shape=(1, 28, 28))\n",
    "    at1 = SeqSelfAttention(attention_activation='sigmoid')(inputs)\n",
    "    at1 = multiply([inputs,at1])\n",
    "    li = Conv2D(32, (5, 5), padding='same', activation='relu')(at1)\n",
    "#     at1 = SeqSelfAttention(attention_activation='sigmoid')(li)\n",
    "#     li = multiply([li,at1])\n",
    "    \n",
    "#     li = multiply([li,at1])\n",
    "    li = MaxPooling2D(pool_size=(2, 2), padding='same')(li)\n",
    "    \n",
    "\n",
    "    li = Conv2D(64, (5, 5), padding='same', activation='relu')(li)\n",
    "#     at1 = SeqSelfAttention(attention_activation='sigmoid')(li)\n",
    "#     li = Multiply()([li,at1])\n",
    "    li = MaxPooling2D(pool_size=(2, 2), padding='same')(li)\n",
    "\n",
    "    li = Conv2D(128, (1, 1), padding='same', activation='relu')(li)\n",
    "#     at1 = SeqSelfAttention(attention_activation='sigmoid')(li)\n",
    "#     li = Multiply()([li,at1])\n",
    "    li = MaxPooling2D(pool_size=(2, 2), padding='same')(li)\n",
    "\n",
    "    li = Flatten()(li)\n",
    "\n",
    "    li = Dense(1024, activation='relu', kernel_constraint=maxnorm(3))(li)\n",
    "    li = Dropout(0.5)(li)\n",
    "    li = Dense(512, activation='relu', kernel_constraint=maxnorm(3))(li)\n",
    "    li = Dropout(0.5)(li)\n",
    "\n",
    "    li = Dense(num_classes, activation='softmax')(li)\n",
    "    model = Model(inputs=[inputs],outputs=[li])\n",
    "    # Compile model\n",
    "    lrate = 0.01\n",
    "    decay = lrate / epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model    \n",
    "\n",
    "\n",
    "def model_cnn(num_classes):\n",
    "    \"\"\"Convolutional Neural Network\n",
    "\n",
    "    The network topology can be summarized as follows:\n",
    "\n",
    "        Convolutional layer with 32 feature maps of size 5×5.\n",
    "        Pooling layer taking the max over 2*2 patches.\n",
    "        Convolutional layer with 64 feature maps of size 5×5.\n",
    "        Pooling layer taking the max over 2*2 patches.\n",
    "        Convolutional layer with 128 feature maps of size 1×1.\n",
    "        Pooling layer taking the max over 2*2 patches.\n",
    "        Flatten layer.\n",
    "        Fully connected layer with 1024 neurons and rectifier activation.\n",
    "        Dropout layer with a probability of 50%.\n",
    "        Fully connected layer with 510 neurons and rectifier activation.\n",
    "        Dropout layer with a probability of 50%.\n",
    "        Output layer.\n",
    "\n",
    "    \"\"\"\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128, (1, 1), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    lrate = 0.01\n",
    "    decay = lrate / epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    #########################################################\n",
    "    # DATA PREPARATION\n",
    "    # The train set has 60k rows and 784 columns, so its shape is (60k,784).\n",
    "    # Each row is a 28 by 28 pixel picture.\n",
    "    # I will reshape the train set to have (60k,1) shape, i.e. each row will contain a 28 by 28 matrix of pixel color values.\n",
    "    # Same for the test set.\n",
    "    #########################################################\n",
    "    # get data\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "    print('train shape: {}'.format(x_train.shape))\n",
    "    print('test shape: {}'.format(x_test.shape))\n",
    "    \n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "\n",
    "    y_train_CNN = y_train  # only labels i.e targets digits\n",
    "    X_train_CNN = x_train.reshape(x_train.shape[0], 1, 28, 28).astype(np.uint8)\n",
    "    print('train shape after reshape: {}'.format(X_train_CNN.shape))\n",
    "\n",
    "    y_test_CNN = y_test  # only labels i.e targets digits\n",
    "    X_test_CNN = x_test.reshape(x_test.shape[0], 1, 28, 28).astype(np.uint8)\n",
    "    print('test shape after reshape: {}'.format(X_test_CNN.shape))\n",
    "\n",
    "    # normalize inputs from 0-255 to 0-1\n",
    "    X_train_CNN = X_train_CNN / 255\n",
    "    X_test_CNN = X_test_CNN / 255\n",
    "\n",
    "    # one hot encode outputs\n",
    "    y_train_CNN = to_categorical(y_train_CNN)\n",
    "    y_test_CNN = to_categorical(y_test_CNN)\n",
    "    num_classes = y_train_CNN.shape[1]\n",
    "\n",
    "    X_train = X_train_CNN\n",
    "    X_val = X_test_CNN\n",
    "    y_train = y_train_CNN\n",
    "    y_val = y_test_CNN\n",
    "\n",
    "    #########################################################\n",
    "    # BUILDE THE MODEL AND EVALUATE IT USING K-FOLD\n",
    "    #########################################################\n",
    "\n",
    "#     kf = KFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "#     kf.get_n_splits(X_train)\n",
    "\n",
    "#     acc_scores = list()\n",
    "\n",
    "#     for fold, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "#         print('\\n Fold %d' % (fold))\n",
    "\n",
    "#         X_tr, X_v = X_train[train_index], X_train[test_index]\n",
    "#         y_tr, y_v = y_train[train_index], y_train[test_index]\n",
    "#         # build the model\n",
    "#         model = model_cnn(num_classes)\n",
    "#         # fit model\n",
    "#         model.fit(\n",
    "#             X_tr,\n",
    "#             y_tr,\n",
    "#             epochs=epochs,\n",
    "#             validation_data=(X_v, y_v),\n",
    "#             verbose=2,\n",
    "#             batch_size=batch_size,\n",
    "#             callbacks=callbacks,\n",
    "#             shuffle=True\n",
    "#         )\n",
    "\n",
    "#         acc = model.evaluate(X_v, y_v, verbose=0)\n",
    "#         acc_scores.append(acc[1])\n",
    "\n",
    "#         print('Fold %d: Accuracy %.2f%%' % (fold, acc[1] * 100))\n",
    "\n",
    "#     print('Accuracy scores: ', acc_scores)\n",
    "\n",
    "#     mean_acc = average(acc_scores)\n",
    "#     standard_deviation_acc = mt.sqrt(sum_of_square_deviation(acc_scores, mean_acc))\n",
    "\n",
    "#     print('=====================')\n",
    "#     print('Mean Accuracy %f' % mean_acc)\n",
    "#     print('=====================')\n",
    "#     print('=====================')\n",
    "#     print('Stdev Accuracy %f' % standard_deviation_acc)\n",
    "#     print('=====================')\n",
    "\n",
    "    model = model_cnn(num_classes)\n",
    "    model.summary()\n",
    "#     Fit the final model\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=callbacks, verbose=2)\n",
    "\n",
    "    # Final evaluation of the model\n",
    "    scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(\"Error: %.2f%%\" % (100 - scores[1] * 100))\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    fig_acc = plt.figure(figsize=(10, 10))\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "#     fig_acc.savefig(\"../Output/model_accuracy_fm_cnn.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 256)         439296    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_18 (SeqSe (None, None, 256)         16449     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, None, 5)           1285      \n",
      "=================================================================\n",
      "Total params: 3,457,030\n",
      "Trainable params: 3,457,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim=10000,\n",
    "                                 output_dim=300,\n",
    "                                 mask_zero=True))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128,\n",
    "                                                       return_sequences=True)))\n",
    "model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(units=5))\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import complexnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension must be 3 but is 4 for 'ff_t2_1/transpose' (op: 'Transpose') with input shapes: [?,247,20], [4].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1618\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension must be 3 but is 4 for 'ff_t2_1/transpose' (op: 'Transpose') with input shapes: [?,247,20], [4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-3bd3c2c17c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mdefine_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-3bd3c2c17c6c>\u001b[0m in \u001b[0;36mdefine_generator\u001b[0;34m(latent_dim, n_classes, out_shape)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mli_imag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mli1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplexnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComplexConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplexnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFT2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;31m#     li = Com()([li_real,li_imag])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m#     complexnn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/complexnn/fft.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFFT2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mpermute_dimensions\u001b[0;34m(x, pattern)\u001b[0m\n\u001b[1;32m   2452\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2453\u001b[0m     \"\"\"\n\u001b[0;32m-> 2454\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose_v2\u001b[0;34m(a, perm, conjugate, name)\u001b[0m\n\u001b[1;32m   1864\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \"\"\"\n\u001b[0;32m-> 1866\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconjugate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mperm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1946\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m  10535\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10536\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m> 10537\u001b[0;31m         \"Transpose\", x=x, perm=perm, name=name)\n\u001b[0m\u001b[1;32m  10538\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10539\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3322\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1786\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1622\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension must be 3 but is 4 for 'ff_t2_1/transpose' (op: 'Transpose') with input shapes: [?,247,20], [4]."
     ]
    }
   ],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,GRU,Bidirectional\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten,multiply\n",
    "from keras.layers import Conv2D,Conv1D,MaxPool1D,BatchNormalization\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv2DTranspose, Lambda\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import layers\n",
    "def Conv1DTranspose(input_tensor, filters, kernel_size, strides=1, padding='same'):\n",
    "    \"\"\"\n",
    "        input_tensor: tensor, with the shape (batch_size, time_steps, dims)\n",
    "        filters: int, output dimension, i.e. the output tensor will have the shape of (batch_size, time_steps, filters)\n",
    "        kernel_size: int, size of the convolution kernel\n",
    "        strides: int, convolution step size\n",
    "        padding: 'same' | 'valid'\n",
    "    \"\"\"\n",
    "    x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), \n",
    "                        strides=(strides, 1), padding=padding,activation='tanh',\n",
    "                       kernel_initializer='he_normal')(x)\n",
    "    x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Com(layers.Layer):\n",
    "\n",
    "      def __init__(self, units=32, input_dim=32):\n",
    "        super(Com, self).__init__()\n",
    "        pass\n",
    "\n",
    "      def call(self, inputs):\n",
    "        return tf.cast(inputs[0]+1j*inputs[1],dtype=tf.complex64)\n",
    "\n",
    "def define_generator(latent_dim=100, n_classes=5,out_shape=(256,3)):\n",
    "    in_label = Input(shape=(n_classes,))\n",
    "    li = Reshape((1,n_classes))(in_label)\n",
    "    li = Conv1DTranspose(li,32,10)\n",
    "#     li = LeakyReLU(alpha=0.2)(li)\n",
    "#     li = Conv1DTranspose(li,64,10)\n",
    "#     li = LeakyReLU(alpha=0.2)(li)\n",
    "#     li = Conv1DTranspose(li,128,10)\n",
    "#     li = LeakyReLU(alpha=0.2)(li)\n",
    "    li = Conv1DTranspose(li,256,10)\n",
    "    li = Reshape((out_shape[0],1))(li)\n",
    "    in_noise = Input(shape=(latent_dim,))\n",
    "    li1 = Reshape((1,latent_dim))(in_noise)\n",
    "#     li1 = Conv1DTranspose(li1,32,10)\n",
    "#     li1 = LeakyReLU(alpha=0.2)(li1)\n",
    "#     li1 = Conv1DTranspose(li1,64,10)\n",
    "#     li1 = LeakyReLU(alpha=0.2)(li1)\n",
    "    li1 = Conv1DTranspose(li1,128,10)\n",
    "#     li1 = LeakyReLU(alpha=0.2)(li1)\n",
    "    li1 = Conv1DTranspose(li1,256,10)\n",
    "    li1 = Reshape((out_shape[0],1))(li1)\n",
    "    li_real = Concatenate()([li,li1])\n",
    "    li_imag = Concatenate()([li,li1])\n",
    "    li = complexnn.conv.ComplexConv1D(10,10)(li_real)\n",
    "    li = complexnn.FFT2()(li)\n",
    "#     li = Com()([li_real,li_imag])\n",
    "#     complexnn.\n",
    "#     li = K.cast(li_real,dtype=tf.complex64)(li_real)\n",
    "#     li = Conv1D(100,40, padding='same',activation='tanh',kernel_initializer='he_normal')(li)\n",
    "#     li = Dropout(.2)(li)\n",
    "#     li = Conv1D(out_shape[1],50, padding='same',activation='tanh',kernel_initializer='he_normal')(li)\n",
    "    model = Model([in_noise,in_label],li)\n",
    "    model.summary()\n",
    "    return model\n",
    "define_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
